df_fl_prev <- read.csv("fl_recipients_prevalence.csv", header = TRUE, check.names = FALSE)
tg_melt <- melt(df_tg_prev)
fl_melt <- melt(df_fl_prev)
p_prev_tg <- ggplot(tg_melt, aes(x = variable , y = OTU, fill = value)) + geom_tile() +
coord_fixed() + scale_fill_gradientn(colours = hm.palette2(10)) + xlab(NULL) +
ylab(NULL) + theme(axis.text=element_text(size=7)) + theme(axis.text.y = element_blank(),
axis.text.x = element_blank()) + theme(legend.position="none")
p_prev_tg
p_prev_fl <- ggplot(fl_melt, aes(x = variable , y = OTU, fill = value)) + geom_tile() +
coord_fixed() + scale_fill_gradientn(colours = hm.palette2(10)) + xlab(NULL) + ylab(NULL) +
theme(axis.text=element_text(size=7)) + theme(axis.text.y = element_blank(),
axis.text.x = element_blank())
p_prev_fl
install.packages("caTools")  # install external package
library(caTools)             # external package providing write.gif function
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F",
"yellow", "#FF7F00", "red", "#7F0000"))
dx <- 400                    # define width
dy <- 400                    # define height
C  <- complex(real = rep(seq(-2.2, 1.0, length.out = dx), each = dy),
imag = rep(seq(-1.2, 1.2, length.out = dy), dx))
C <- matrix(C, dy, dx)       # reshape as square matrix of complex numbers
Z <- 0                       # initialize Z to zero
X <- array(0, c(dy, dx, 20)) # initialize output 3D array
for (k in 1:20) {            # loop with 20 iterations
Z <- Z^2 + C               # the central difference equation
X[, , k] <- exp(-abs(Z))   # capture results
}
write.gif(X, "Mandelbrot.gif", col = jet.colors, delay = 100)
install.packages("caTools")  # install external package
library(caTools)             # external package providing write.gif function
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F",
"yellow", "#FF7F00", "red", "#7F0000"))
dx <- 400                    # define width
dy <- 400                    # define height
C  <- complex(real = rep(seq(-2.2, 1.0, length.out = dx), each = dy),
imag = rep(seq(-1.2, 1.2, length.out = dy), dx))
C <- matrix(C, dy, dx)       # reshape as square matrix of complex numbers
Z <- 0                       # initialize Z to zero
X <- array(0, c(dy, dx, 20)) # initialize output 3D array
for (k in 1:20) {            # loop with 20 iterations
Z <- Z^2 + C               # the central difference equation
X[, , k] <- exp(-abs(Z))   # capture results
}
write.gif(X, "Mandelbrot.gif", col = jet.colors, delay = 100)
install.packages(c("ade4", "backports", "BH", "callr", "caret", "cowplot", "curl", "dbplyr", "ddalpha", "digest", "DRR", "foreach", "fpc", "GUniFrac", "haven", "Hmisc", "hms", "htmlTable", "htmlwidgets", "irlba", "iterators", "knitr", "lava", "lubridate", "MASS", "matrixStats", "mgcv", "mvtnorm", "nlme", "openssl", "phangorn", "Rcpp", "RcppArmadillo", "RCurl", "recipes", "reprex", "reshape2", "rlang", "rpart", "rprojroot", "tibble", "tidyr", "vegan", "viridis", "viridisLite", "withr", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages(c("ade4", "backports", "BH", "callr", "caret", "cowplot", "curl", "dbplyr", "ddalpha", "digest", "DRR", "foreach", "fpc", "GUniFrac", "haven", "Hmisc", "hms", "htmlTable", "htmlwidgets", "irlba", "iterators", "knitr", "lava", "lubridate", "MASS", "matrixStats", "mgcv", "mvtnorm", "nlme", "openssl", "phangorn", "Rcpp", "RcppArmadillo", "RCurl", "recipes", "reprex", "reshape2", "rlang", "rpart", "rprojroot", "tibble", "tidyr", "vegan", "viridis", "viridisLite", "withr", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages(c("ade4", "backports", "BH", "callr", "caret", "cowplot", "curl", "dbplyr", "ddalpha", "digest", "DRR", "foreach", "fpc", "GUniFrac", "haven", "Hmisc", "hms", "htmlTable", "htmlwidgets", "irlba", "iterators", "knitr", "lava", "lubridate", "MASS", "matrixStats", "mgcv", "mvtnorm", "nlme", "openssl", "phangorn", "Rcpp", "RcppArmadillo", "RCurl", "recipes", "reprex", "reshape2", "rlang", "rpart", "rprojroot", "tibble", "tidyr", "vegan", "viridis", "viridisLite", "withr", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages(c("ade4", "backports", "BH", "callr", "caret", "cowplot", "curl", "dbplyr", "ddalpha", "digest", "DRR", "foreach", "fpc", "GUniFrac", "haven", "Hmisc", "hms", "htmlTable", "htmlwidgets", "irlba", "iterators", "knitr", "lava", "lubridate", "MASS", "matrixStats", "mgcv", "mvtnorm", "nlme", "openssl", "phangorn", "Rcpp", "RcppArmadillo", "RCurl", "recipes", "reprex", "reshape2", "rlang", "rpart", "rprojroot", "tibble", "tidyr", "vegan", "viridis", "viridisLite", "withr", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages(c("ade4", "backports", "BH", "callr", "caret", "cowplot", "curl", "dbplyr", "ddalpha", "digest", "DRR", "foreach", "fpc", "GUniFrac", "haven", "Hmisc", "hms", "htmlTable", "htmlwidgets", "irlba", "iterators", "knitr", "lava", "lubridate", "MASS", "matrixStats", "mgcv", "mvtnorm", "nlme", "openssl", "phangorn", "Rcpp", "RcppArmadillo", "RCurl", "recipes", "reprex", "reshape2", "rlang", "rpart", "rprojroot", "tibble", "tidyr", "vegan", "viridis", "viridisLite", "withr", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages(c("ade4", "backports", "BH", "callr", "caret", "cowplot", "curl", "dbplyr", "ddalpha", "digest", "DRR", "foreach", "fpc", "GUniFrac", "haven", "Hmisc", "hms", "htmlTable", "htmlwidgets", "irlba", "iterators", "knitr", "lava", "lubridate", "MASS", "matrixStats", "mgcv", "mvtnorm", "nlme", "openssl", "phangorn", "Rcpp", "RcppArmadillo", "RCurl", "recipes", "reprex", "reshape2", "rlang", "rpart", "rprojroot", "tibble", "tidyr", "vegan", "viridis", "viridisLite", "withr", "XML", "xml2", "xts", "yaml", "zoo"))
##############################################################################################################################################
# This script performs supervised classification of a normalised OTU table.
# Version: 0.9
# 2018-02-05  Author: Adam Sorbie
#
#  Please set the directory of the script as the working folder (e.g C:/studyname/NGS-Data/Microbiome_classification)
#' Note: the path is denoted by forward slash "/"
setwd("C:/Users/PhD/Supervised_Classification/Microbiome_Classification")  #<--- CHANGE ACCORDINGLY !!!
# Enter name of OTU table file:
input_otu_table <- "merged_otu.tab"        #<--- CHANGE ACCORDINGLY !!!
# Enter name of mapping file:
mapping_file <- "merged_map.tab"         #<--- CHANGE ACCORDINGLY !!!
# Please select model.
# 0 = Random-Forest Model (default) -
# 1 = Support Vector Machine -
# 2 = eXtreme Gradient Boosting -
model <- 1       #<--- CHANGE ACCORDINGLY !!!
# Please select cross-validation method:
# 0 = k-fold Cross-validation (default) -
# 1 = Repeated k-fold Cross Validation -
# 2 = Leave-one-out cross validation -
cv <- 1       #<--- CHANGE ACCORDINGLY !!!
# Please give the column where the categorical variable is found
col_name <- "Phenotype"        #<--- CHANGE ACCORDINGLY !!!
######                  NO CHANGES REQUIRED BELOW THIS LINE                 ######
##################################################################################
######                             Main Script                              ######
##################################################################################
###################       Load all required libraries     ########################
# Check if required packages are already installed, and install if missing
packages <-c("caret", "randomForest", "ROCR", "plyr", "rfUtilities")
# Function to check whether the package is installed
InsPack <- function(pack)
{
if ((pack %in% installed.packages()) == FALSE) {
install.packages(pack,repos = "http://cloud.r-project.org/")
}
}
# Applying the installation on the list of packages
lapply(packages, InsPack)
# Make the libraries
lib <- lapply(packages, require, character.only = TRUE)
# Check if it was possible to install all required libraries
flag <- all(as.logical(lib))
# read data
otu <- read.table(input_otu_table, sep="\t", header=T, row.names=1, stringsAsFactors=TRUE, comment.char="", check.names=FALSE)
mapping <- read.table(mapping_file, sep="\t", header=T, row.names=1, stringsAsFactors=TRUE, comment.char="", check.names=FALSE)
# scale pre-preprocessed training data and merge phenotype column from metadata
otu_table_scaled <- scale(otu, center = TRUE, scale = TRUE)
otu_table_scaled_labels <- data.frame(t(otu_table_scaled))
otu_table_scaled_labels[col_name] <- mapping[rownames(otu_table_scaled_labels), col_name]
# set random seed to 42
set.seed(42)
#split into training and test
trainIndex = createDataPartition(otu_table_scaled_labels$Phenotype,
p=0.7, list=FALSE,times=1)
training = otu_table_scaled_labels[trainIndex,]
test = otu_table_scaled_labels[-trainIndex,]
# set X and y
X_train <- training[,1:(ncol(training)-1)]
y_train <- training[ , ncol(training)]
X_test <- test[,1:(ncol(test)-1)]
# for comparing model predictions against actual categories
actual <- as.character(test[ , ncol(test)])
# cross validation method
if (cv == 0) {
fit_ctrl <- trainControl(method = "cv", number = 10)
} else if (cv == 1) {
fit_ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
} else if (cv == 2) {
fit_ctrl <- trainControl(method = "LOOCV")
} else {
print("Error please enter a valid selection:
0 = k-fold cross validation
1 = repeated k-fold cross validation
2 = leave-one-out cross validation")
}
if (model == 0) {
mtryStart <- floor(sqrt(ncol(X_train)))
mtryexpand <- seq(from = mtryStart-10, to= mtryStart+10, by=2)
tunegrid <- expand.grid(.mtry=mtryexpand)
RF_cv <- train(X_train, y_train, method="rf", ntree=501 ,
tuneGrid=tunegrid, trControl=fit_ctrl)
RF_classify <- randomForest(X_train, y_train, importance = TRUE, proximity = TRUE)
predictions <- predict(RF_cv, newdata = X_test)
samples <- row.names(X_test)
pred_df <- data.frame(samples, actual, predictions)
print(pred_df)
pred_df$Correct <- pred_df$actual == pred_df$predictions
result <- confusionMatrix(predictions, actual)
metrics <- data.frame(cbind(t(result$positive),t(result$byClass), t(result$overall)))
write.table(pred_df, file = "random_forest_predictions.tsv", sep="\t", row.names = FALSE) # output to folders
write.table(result$table, file = "confusion_matrix.tsv", sep="\t", row.names = FALSE)
write.table(metrics, file="metrics.tsv", sep="\t", row.names = FALSE)
} else if (model == 1) {
svm_cv <- train(X_train, y_train, method="svmLinear", trControl= fit_ctrl )
predictions <- predict(svm_cv, newdata = X_test)
print(svm_cv)
} else if (model == 2) {
print("Sorry, this model is not yet available, please choose another")
} else {
print("Error, please enter a valid selection:
0 = Random Forest
1 = SVM
2 = eXtreme gradient boosting")}
print(predictions)
setwd("C:/Users/PhD/Supervised_Classification/Microbiome_Classification")
##############################################################################################################################################
# This script performs supervised classification of a normalised OTU table.
# Version: 0.9
# 2018-02-05  Author: Adam Sorbie
#
#  Please set the directory of the script as the working folder (e.g C:/studyname/NGS-Data/Microbiome_classification)
#' Note: the path is denoted by forward slash "/"
setwd("C:/Users/PhD/Supervised_Classification/Microbiome_Classification")  #<--- CHANGE ACCORDINGLY !!!
# Enter name of OTU table file:
input_otu_table <- "merged_otu.tab"        #<--- CHANGE ACCORDINGLY !!!
# Enter name of mapping file:
mapping_file <- "merged_map.tab"         #<--- CHANGE ACCORDINGLY !!!
# Please select model.
# 0 = Random-Forest Model (default) -
# 1 = Support Vector Machine -
# 2 = eXtreme Gradient Boosting -
model <- 1       #<--- CHANGE ACCORDINGLY !!!
# Please select cross-validation method:
# 0 = k-fold Cross-validation (default) -
# 1 = Repeated k-fold Cross Validation -
# 2 = Leave-one-out cross validation -
cv <- 1       #<--- CHANGE ACCORDINGLY !!!
# Please give the column where the categorical variable is found
col_name <- "Phenotype"        #<--- CHANGE ACCORDINGLY !!!
######                  NO CHANGES REQUIRED BELOW THIS LINE                 ######
##################################################################################
######                             Main Script                              ######
##################################################################################
###################       Load all required libraries     ########################
# Check if required packages are already installed, and install if missing
packages <-c("caret", "randomForest", "ROCR", "plyr", "rfUtilities")
# Function to check whether the package is installed
InsPack <- function(pack)
{
if ((pack %in% installed.packages()) == FALSE) {
install.packages(pack,repos = "http://cloud.r-project.org/")
}
}
# Applying the installation on the list of packages
lapply(packages, InsPack)
# Make the libraries
lib <- lapply(packages, require, character.only = TRUE)
# Check if it was possible to install all required libraries
flag <- all(as.logical(lib))
# read data
otu <- read.table(input_otu_table, sep="\t", header=T, row.names=1, stringsAsFactors=TRUE, comment.char="", check.names=FALSE)
mapping <- read.table(mapping_file, sep="\t", header=T, row.names=1, stringsAsFactors=TRUE, comment.char="", check.names=FALSE)
# scale pre-preprocessed training data and merge phenotype column from metadata
otu_table_scaled <- scale(otu, center = TRUE, scale = TRUE)
otu_table_scaled_labels <- data.frame(t(otu_table_scaled))
otu_table_scaled_labels[col_name] <- mapping[rownames(otu_table_scaled_labels), col_name]
# set random seed to 42
set.seed(42)
#split into training and test
trainIndex = createDataPartition(otu_table_scaled_labels$Phenotype,
p=0.7, list=FALSE,times=1)
training = otu_table_scaled_labels[trainIndex,]
test = otu_table_scaled_labels[-trainIndex,]
# set X and y
X_train <- training[,1:(ncol(training)-1)]
y_train <- training[ , ncol(training)]
X_test <- test[,1:(ncol(test)-1)]
# for comparing model predictions against actual categories
actual <- as.character(test[ , ncol(test)])
# cross validation method
if (cv == 0) {
fit_ctrl <- trainControl(method = "cv", number = 10)
} else if (cv == 1) {
fit_ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
} else if (cv == 2) {
fit_ctrl <- trainControl(method = "LOOCV")
} else {
print("Error please enter a valid selection:
0 = k-fold cross validation
1 = repeated k-fold cross validation
2 = leave-one-out cross validation")
}
if (model == 0) {
mtryStart <- floor(sqrt(ncol(X_train)))
mtryexpand <- seq(from = mtryStart-10, to= mtryStart+10, by=2)
tunegrid <- expand.grid(.mtry=mtryexpand)
RF_cv <- train(X_train, y_train, method="rf", ntree=501 ,
tuneGrid=tunegrid, trControl=fit_ctrl)
RF_classify <- randomForest(X_train, y_train, importance = TRUE, proximity = TRUE)
predictions <- predict(RF_cv, newdata = X_test)
samples <- row.names(X_test)
pred_df <- data.frame(samples, actual, predictions)
print(pred_df)
pred_df$Correct <- pred_df$actual == pred_df$predictions
result <- confusionMatrix(predictions, actual)
metrics <- data.frame(cbind(t(result$positive),t(result$byClass), t(result$overall)))
write.table(pred_df, file = "random_forest_predictions.tsv", sep="\t", row.names = FALSE) # output to folders
write.table(result$table, file = "confusion_matrix.tsv", sep="\t", row.names = FALSE)
write.table(metrics, file="metrics.tsv", sep="\t", row.names = FALSE)
} else if (model == 1) {
svm_cv <- train(X_train, y_train, method="svmLinear", trControl= fit_ctrl ) #tunegrid
predictions <- predict(svm_cv, newdata = X_test)
pred_df <- data.frame(samples, actual, predictions)
print(pred_df)
pred_df$Correct <- pred_df$actual == pred_df$predictions
result <- confusionMatrix(predictions, actual)
print(svm_cv)
} else if (model == 2) {
print("Sorry, this model is not yet available, please choose another")
} else {
print("Error, please enter a valid selection:
0 = Random Forest
1 = SVM
2 = eXtreme gradient boosting")}
##############################################################################################################################################
# This script performs supervised classification of a normalised OTU table.
# Version: 0.9
# 2018-02-05  Author: Adam Sorbie
#
#  Please set the directory of the script as the working folder (e.g C:/studyname/NGS-Data/Microbiome_classification)
#' Note: the path is denoted by forward slash "/"
setwd("C:/Users/PhD/Supervised_Classification/Microbiome_Classification")  #<--- CHANGE ACCORDINGLY !!!
# Enter name of OTU table file:
input_otu_table <- "merged_otu.tab"        #<--- CHANGE ACCORDINGLY !!!
# Enter name of mapping file:
mapping_file <- "merged_map.tab"         #<--- CHANGE ACCORDINGLY !!!
# Please select model.
# 0 = Random-Forest Model (default) -
# 1 = Support Vector Machine -
# 2 = eXtreme Gradient Boosting -
model <- 1       #<--- CHANGE ACCORDINGLY !!!
# Please select cross-validation method:
# 0 = k-fold Cross-validation (default) -
# 1 = Repeated k-fold Cross Validation -
# 2 = Leave-one-out cross validation -
cv <- 1       #<--- CHANGE ACCORDINGLY !!!
# Please give the column where the categorical variable is found
col_name <- "Phenotype"        #<--- CHANGE ACCORDINGLY !!!
######                  NO CHANGES REQUIRED BELOW THIS LINE                 ######
##################################################################################
######                             Main Script                              ######
##################################################################################
###################       Load all required libraries     ########################
# Check if required packages are already installed, and install if missing
packages <-c("caret", "randomForest", "ROCR", "plyr", "rfUtilities")
# Function to check whether the package is installed
InsPack <- function(pack)
{
if ((pack %in% installed.packages()) == FALSE) {
install.packages(pack,repos = "http://cloud.r-project.org/")
}
}
# Applying the installation on the list of packages
lapply(packages, InsPack)
# Make the libraries
lib <- lapply(packages, require, character.only = TRUE)
# Check if it was possible to install all required libraries
flag <- all(as.logical(lib))
# read data
otu <- read.table(input_otu_table, sep="\t", header=T, row.names=1, stringsAsFactors=TRUE, comment.char="", check.names=FALSE)
mapping <- read.table(mapping_file, sep="\t", header=T, row.names=1, stringsAsFactors=TRUE, comment.char="", check.names=FALSE)
# scale pre-preprocessed training data and merge phenotype column from metadata
otu_table_scaled <- scale(otu, center = TRUE, scale = TRUE)
otu_table_scaled_labels <- data.frame(t(otu_table_scaled))
otu_table_scaled_labels[col_name] <- mapping[rownames(otu_table_scaled_labels), col_name]
# set random seed to 42
set.seed(42)
#split into training and test
trainIndex = createDataPartition(otu_table_scaled_labels$Phenotype,
p=0.7, list=FALSE,times=1)
training = otu_table_scaled_labels[trainIndex,]
test = otu_table_scaled_labels[-trainIndex,]
# set X and y
X_train <- training[,1:(ncol(training)-1)]
y_train <- training[ , ncol(training)]
X_test <- test[,1:(ncol(test)-1)]
# for comparing model predictions against actual categories
actual <- as.character(test[ , ncol(test)])
# cross validation method
if (cv == 0) {
fit_ctrl <- trainControl(method = "cv", number = 10)
} else if (cv == 1) {
fit_ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
} else if (cv == 2) {
fit_ctrl <- trainControl(method = "LOOCV")
} else {
print("Error please enter a valid selection:
0 = k-fold cross validation
1 = repeated k-fold cross validation
2 = leave-one-out cross validation")
}
if (model == 0) {
mtryStart <- floor(sqrt(ncol(X_train)))
mtryexpand <- seq(from = mtryStart-10, to= mtryStart+10, by=2)
tunegrid <- expand.grid(.mtry=mtryexpand)
RF_cv <- train(X_train, y_train, method="rf", ntree=501 ,
tuneGrid=tunegrid, trControl=fit_ctrl)
RF_classify <- randomForest(X_train, y_train, importance = TRUE, proximity = TRUE)
predictions <- predict(RF_cv, newdata = X_test)
samples <- row.names(X_test)
pred_df <- data.frame(samples, actual, predictions)
print(pred_df)
pred_df$Correct <- pred_df$actual == pred_df$predictions
result <- confusionMatrix(predictions, actual)
metrics <- data.frame(cbind(t(result$positive),t(result$byClass), t(result$overall)))
write.table(pred_df, file = "random_forest_predictions.tsv", sep="\t", row.names = FALSE) # output to folders
write.table(result$table, file = "confusion_matrix.tsv", sep="\t", row.names = FALSE)
write.table(metrics, file="metrics.tsv", sep="\t", row.names = FALSE)
} else if (model == 1) {
svm_cv <- train(X_train, y_train, method="svmLinear", trControl= fit_ctrl ) #tunegrid
predictions <- predict(svm_cv, newdata = X_test)
samples <- row.names(X_test)
pred_df <- data.frame(samples, actual, predictions)
print(pred_df)
pred_df$Correct <- pred_df$actual == pred_df$predictions
result <- confusionMatrix(predictions, actual)
print(svm_cv)
} else if (model == 2) {
print("Sorry, this model is not yet available, please choose another")
} else {
print("Error, please enter a valid selection:
0 = Random Forest
1 = SVM
2 = eXtreme gradient boosting")}
print(result)
##############################################################################################################################################
# This script performs supervised classification of a normalised OTU table.
# Version: 0.9
# 2018-02-05  Author: Adam Sorbie
#
#  Please set the directory of the script as the working folder (e.g C:/studyname/NGS-Data/Microbiome_classification)
#' Note: the path is denoted by forward slash "/"
setwd("C:/Users/PhD/Supervised_Classification/Microbiome_Classification")  #<--- CHANGE ACCORDINGLY !!!
# Enter name of OTU table file:
input_otu_table <- "merged_otu.tab"        #<--- CHANGE ACCORDINGLY !!!
# Enter name of mapping file:
mapping_file <- "merged_map.tab"         #<--- CHANGE ACCORDINGLY !!!
# Please select model.
# 0 = Random-Forest Model (default) -
# 1 = Support Vector Machine -
# 2 = eXtreme Gradient Boosting -
model <- 0       #<--- CHANGE ACCORDINGLY !!!
# Please select cross-validation method:
# 0 = k-fold Cross-validation (default) -
# 1 = Repeated k-fold Cross Validation -
# 2 = Leave-one-out cross validation -
cv <- 1       #<--- CHANGE ACCORDINGLY !!!
# Please give the column where the categorical variable is found
col_name <- "Phenotype"        #<--- CHANGE ACCORDINGLY !!!
######                  NO CHANGES REQUIRED BELOW THIS LINE                 ######
##################################################################################
######                             Main Script                              ######
##################################################################################
###################       Load all required libraries     ########################
# Check if required packages are already installed, and install if missing
packages <-c("caret", "randomForest", "ROCR", "plyr", "rfUtilities")
# Function to check whether the package is installed
InsPack <- function(pack)
{
if ((pack %in% installed.packages()) == FALSE) {
install.packages(pack,repos = "http://cloud.r-project.org/")
}
}
# Applying the installation on the list of packages
lapply(packages, InsPack)
# Make the libraries
lib <- lapply(packages, require, character.only = TRUE)
# Check if it was possible to install all required libraries
flag <- all(as.logical(lib))
# read data
otu <- read.table(input_otu_table, sep="\t", header=T, row.names=1, stringsAsFactors=TRUE, comment.char="", check.names=FALSE)
mapping <- read.table(mapping_file, sep="\t", header=T, row.names=1, stringsAsFactors=TRUE, comment.char="", check.names=FALSE)
# scale pre-preprocessed training data and merge phenotype column from metadata
otu_table_scaled <- scale(otu, center = TRUE, scale = TRUE)
otu_table_scaled_labels <- data.frame(t(otu_table_scaled))
otu_table_scaled_labels[col_name] <- mapping[rownames(otu_table_scaled_labels), col_name]
# set random seed to 42
set.seed(42)
#split into training and test
trainIndex = createDataPartition(otu_table_scaled_labels$Phenotype,
p=0.7, list=FALSE,times=1)
training = otu_table_scaled_labels[trainIndex,]
test = otu_table_scaled_labels[-trainIndex,]
# set X and y
X_train <- training[,1:(ncol(training)-1)]
y_train <- training[ , ncol(training)]
X_test <- test[,1:(ncol(test)-1)]
# for comparing model predictions against actual categories
actual <- as.character(test[ , ncol(test)])
# cross validation method
if (cv == 0) {
fit_ctrl <- trainControl(method = "cv", number = 10)
} else if (cv == 1) {
fit_ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
} else if (cv == 2) {
fit_ctrl <- trainControl(method = "LOOCV")
} else {
print("Error please enter a valid selection:
0 = k-fold cross validation
1 = repeated k-fold cross validation
2 = leave-one-out cross validation")
}
if (model == 0) {
mtryStart <- floor(sqrt(ncol(X_train)))
mtryexpand <- seq(from = mtryStart-10, to= mtryStart+10, by=2)
tunegrid <- expand.grid(.mtry=mtryexpand)
RF_cv <- train(X_train, y_train, method="rf", ntree=501 ,
tuneGrid=tunegrid, trControl=fit_ctrl)
RF_classify <- randomForest(X_train, y_train, importance = TRUE, proximity = TRUE)
predictions <- predict(RF_cv, newdata = X_test)
samples <- row.names(X_test)
pred_df <- data.frame(samples, actual, predictions)
print(pred_df)
pred_df$Correct <- pred_df$actual == pred_df$predictions
result <- confusionMatrix(predictions, actual)
metrics <- data.frame(cbind(t(result$positive),t(result$byClass), t(result$overall)))
write.table(pred_df, file = "random_forest_predictions.tsv", sep="\t", row.names = FALSE) # output to folders
write.table(result$table, file = "confusion_matrix.tsv", sep="\t", row.names = FALSE)
write.table(metrics, file="metrics.tsv", sep="\t", row.names = FALSE)
} else if (model == 1) {
svm_cv <- train(X_train, y_train, method="svmLinear", trControl= fit_ctrl ) #tunegrid
predictions <- predict(svm_cv, newdata = X_test)
samples <- row.names(X_test)
pred_df <- data.frame(samples, actual, predictions)
print(pred_df)
pred_df$Correct <- pred_df$actual == pred_df$predictions
result <- confusionMatrix(predictions, actual)
print(svm_cv)
} else if (model == 2) {
print("Sorry, this model is not yet available, please choose another")
} else {
print("Error, please enter a valid selection:
0 = Random Forest
1 = SVM
2 = eXtreme gradient boosting")}
print(RF_cv)
print(predictions)
print(result)
print(RF_classify)
print(RF_cv)
print(RF_cv$results)
print(RF_cv$pred)
print(RF_cv$method)
View(RF_cv)
View(RF_classify)
RF_cv$modelInfo
RF_cv$modelType
RF_cv$results
mtry_imp <- RF_cv[order("results")]
View(mtry_imp)
mtry_imp <- RF_cv$results[order(Accuracy)
mtry_imp <- RF_cv$results[order("Accuracy")]
RF_cv[order(RF_cv$results), ]
RF_cv[order(RF_cv$results)]
RF_cv$results[order(RF_cv$results$Accuracy)]
RF_cv[order(RF_cv$results$Accuracy)]
mtry_best <- as.data.frame(RF_cv$results)
mtry_best
mtry_best[order(mtry_best$Accuracy)]
